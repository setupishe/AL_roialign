{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob, shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = [\n",
    "    \"train2007\",\n",
    "    \"train2012\",\n",
    "    \"val2007\",\n",
    "    \"val2012\",\n",
    "]\n",
    "\n",
    "train_list = [\n",
    "    f\"./images/{folder}/{x}\"\n",
    "    for folder in lst\n",
    "    for x in os.listdir(os.path.join(\"/home/setupishe/datasets/VOC/images\", folder))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_list = [\n",
    "    f\"./images/test2007/{x}\"\n",
    "    for x in os.listdir(\"/home/setupishe/datasets/VOC/images/test2007\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/home/setupishe/datasets/VOC/VOC_train.txt\", \"w\") as f:\n",
    "    f.writelines([x + \"\\n\" for x in train_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/home/setupishe/datasets/VOC/VOC_val.txt\", \"w\") as f:\n",
    "    f.writelines([x + \"\\n\" for x in test_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob, shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_shape(img_path):\n",
    "    with Image.open(img_path) as img:\n",
    "        width, height = img.size\n",
    "    return height, width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def force_mkdir(directory):\n",
    "    if os.path.isdir(directory):\n",
    "        shutil.rmtree(directory)\n",
    "    os.mkdir(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, shutil, glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jpg2txt(inp):\n",
    "    return inp.replace(\"/images\", \"/labels\").replace(\".jpg\", \".txt\")\n",
    "\n",
    "\n",
    "def txt2jpg(inp):\n",
    "    return inp.replace(\"/labels\", \"/images\").replace(\".txt\", \".jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21503/21503 [00:01<00:00, 13256.40it/s]\n"
     ]
    }
   ],
   "source": [
    "for file in tqdm(\n",
    "    glob.glob(\"/home/setupishe/datasets/VOC/images/**/*.jpg\", recursive=True)\n",
    "):\n",
    "    to_folder = \"val\" if \"test2007\" in file else \"train\"\n",
    "    from_folder_name = file.split(\"/\")[-2]\n",
    "\n",
    "    for func in [lambda x: x, jpg2txt]:\n",
    "        to_path = func(file).replace(from_folder_name, to_folder)\n",
    "        shutil.copy(func(file), to_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in glob.glob(\"/home/setupishe/datasets/VOC/*txt\"):\n",
    "    with open(file, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "    new_lines = []\n",
    "    for line in lines:\n",
    "        from_folder_name = line.split(\"/\")[-2]\n",
    "        to_folder = \"val\" if \"test2007\" in line else \"train\"\n",
    "        new_lines.append(line.replace(from_folder_name, to_folder))\n",
    "    with open(file, \"w\") as f:\n",
    "        f.writelines(new_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/home/setupishe/datasets/VOC/val.txt\", \"r\") as f:\n",
    "    files = [x.rstrip(\"\\n\") for x in f.readlines()]\n",
    "    for file in files:\n",
    "        full_path = os.path.join(\"/home/setupishe/datasets/VOC\", file)\n",
    "        if not os.path.getsize(full_path):\n",
    "            print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/home/setupishe/datasets/coco/train2017_0.2.txt\", \"r\") as f:\n",
    "    lines = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = \"/home/setupishe/ultralytics/runs/detect/confidences_0.6/weights/best.pt\"\n",
    "\n",
    "conf_path = \"/\".join(weights.split(\"/\")[:-2])\n",
    "conf_path = \"/home/setupishe/ultralytics/runs/detect/temp6\" + \"/best_conf.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(conf_path, \"r\") as f:\n",
    "    conf = float(f.readline())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.46446446446446443"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [os.path.basename(x)[:-1] for x in lines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_name = \"imgs_0.2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "force_mkdir(folder_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_shape(img_path):\n",
    "    with Image.open(img_path) as img:\n",
    "        width, height = img.size\n",
    "    return height, width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def txt2jpg(inp):\n",
    "    return inp.replace(\"/labels\", \"/images\").replace(\".txt\", \".jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seg2bbox(filepath, to_path):\n",
    "    with open(filepath, \"r\") as f:\n",
    "        lines = [x.rstrip(\"\\n\") for x in f.readlines()]\n",
    "    new_lines = []\n",
    "    for line in lines:\n",
    "        lst = line.split()\n",
    "        new_line = [lst[0]]\n",
    "\n",
    "        coords = [float(x) for x in lst[1:]]\n",
    "        h, w = get_shape(txt2jpg(filepath))\n",
    "        first = [x for i, x in enumerate(coords) if i % 2 == 0]\n",
    "        second = [x for i, x in enumerate(coords) if i % 2 == 1]\n",
    "        for i in range(len(first)):\n",
    "            first[i] = int(first[i] * w)\n",
    "            second[i] = int(second[i] * h)\n",
    "\n",
    "        xmin = min(first)\n",
    "        xmax = max(first)\n",
    "        ymin = min(second)\n",
    "        ymax = max(second)\n",
    "\n",
    "        width = (xmax - xmin) / w\n",
    "        height = (ymax - ymin) / h\n",
    "        xc = (xmax + xmin) / w / 2\n",
    "        yc = (ymax + ymin) / h / 2\n",
    "\n",
    "        new_lines.append(\n",
    "            \" \".join([str(item) for item in [lst[0], xc, yc, width, height]]) + \"\\n\"\n",
    "        )\n",
    "    with open(to_path, \"w\") as f:\n",
    "        f.writelines(new_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/118287 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 118287/118287 [01:10<00:00, 1677.78it/s]\n"
     ]
    }
   ],
   "source": [
    "filelist = glob.glob(\"/home/setupishe/datasets/coco/images/train2017/*jpg\")\n",
    "for file in tqdm(filelist):\n",
    "    label_file = file.replace(\"images\", \"labels\").replace(\"jpg\", \"txt\")\n",
    "    if os.path.exists(label_file):\n",
    "        seg2bbox(label_file, file.replace(\"jpg\", \"txt\"))\n",
    "    else:\n",
    "        os.mknod(file.replace(\"txt\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### remainder embeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_name = \"remainder_imgs_0.2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "force_mkdir(folder_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 118287/118287 [01:48<00:00, 1090.82it/s]\n"
     ]
    }
   ],
   "source": [
    "filelist = glob.glob(\"/home/setupishe/datasets/coco/images/train2017/*jpg\")\n",
    "for file in tqdm(filelist):\n",
    "    if os.path.basename(file) not in names:\n",
    "        shutil.copy(file, os.path.join(folder_name, os.path.basename(file)))\n",
    "        label_file = file.replace(\"images\", \"labels\").replace(\"jpg\", \"txt\")\n",
    "        if os.path.exists(label_file):\n",
    "            seg2bbox(\n",
    "                label_file, os.path.join(folder_name, os.path.basename(label_file))\n",
    "            )\n",
    "        else:\n",
    "            os.mknod(label_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "запускаем `produce_detection_embeddings.py`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "запускаем `preprocess_embedding_pool.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in glob.glob(\"remainder_embeds_reduced_0.2/**/*npy\", recursive=True):\n",
    "    if len(os.path.basename(file).split(\"_\")) == 2:\n",
    "        os.remove(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in glob.glob(\"rembeds_reduced_0.2/**/*npy\", recursive=True):\n",
    "    if len(os.path.basename(file).split(\"_\")) == 2:\n",
    "        os.remove(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "запускаем `testing_embeds.ipynb`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniq = set()\n",
    "for file in os.listdir(\"test_folder\"):\n",
    "    uniq.add(file.split(\"_\")[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13332"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(uniq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_num = 118287 * 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_bgs = [x + \".jpg\" for x in random.sample(list(uniq), int(target_num * (1 - 0.008)))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ищем свободные не использованные фоны"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "free_bgs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 118287/118287 [00:00<00:00, 399844.65it/s]\n"
     ]
    }
   ],
   "source": [
    "for file in tqdm(\n",
    "    glob.glob(\"/home/setupishe/datasets/coco/labels/train*/**/*txt\", recursive=True)\n",
    "):\n",
    "    name = os.path.basename(file)\n",
    "    if not os.path.getsize(file) and name not in names:\n",
    "        free_bgs.append(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "bgs = [\n",
    "    os.path.basename(x).replace(\"txt\", \"jpg\")\n",
    "    for x in random.sample(free_bgs, int(target_num * 0.008))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/home/setupishe/datasets/coco/train2017_0.3_active.txt\", \"w\") as f:\n",
    "    f.writelines([f\"./images/train2017/{x}\\n\" for x in names + not_bgs + bgs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "int_frac = 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\n",
    "    \"/home/setupishe/ultralytics/ultralytics/cfg/datasets/coco.yaml\", \"r\"\n",
    ") as from_file:\n",
    "    lines = from_file.readlines()\n",
    "\n",
    "for i, line in enumerate(lines):\n",
    "    if \"train: train2017.txt\" in line:\n",
    "        lines[i] = lines[i].replace(\"train2017.txt\", f\"train2017_{int_frac}_active.txt\")\n",
    "with open(\n",
    "    f\"/home/setupishe/ultralytics/ultralytics/cfg/datasets/coco_{int_frac}_active.yaml\",\n",
    "    \"w\",\n",
    ") as to_file:\n",
    "    to_file.writelines(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29.452413320541382"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.ndimage import binary_dilation\n",
    "import time\n",
    "\n",
    "\n",
    "# Define the function for dilation\n",
    "def dilate_3d_spherical(input_array, radius):\n",
    "    \"\"\"\n",
    "    Dilate a 3D binary array using a spherical kernel of a given radius.\n",
    "\n",
    "    Parameters:\n",
    "        input_array (numpy.ndarray): 3D binary array to be dilated.\n",
    "        radius (int): Radius of the spherical kernel.\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: Dilated 3D array.\n",
    "    \"\"\"\n",
    "    # Generate the spherical kernel using efficient broadcasting\n",
    "    size = 2 * radius + 1\n",
    "    x, y, z = np.ogrid[:size, :size, :size]\n",
    "    center = radius\n",
    "    distance = np.sqrt((x - center) ** 2 + (y - center) ** 2 + (z - center) ** 2)\n",
    "    structuring_element = distance <= radius\n",
    "\n",
    "    # Perform the dilation\n",
    "    dilated_array = binary_dilation(input_array, structure=structuring_element)\n",
    "\n",
    "    return dilated_array\n",
    "\n",
    "\n",
    "# Create a large 3D binary array for testing\n",
    "array_size = (512, 512, 512)  # Size of the array\n",
    "large_array = np.zeros(array_size, dtype=bool)\n",
    "\n",
    "# Add some random points to the array to act as seeds for dilation\n",
    "np.random.seed(42)\n",
    "num_points = 1000  # Number of random points\n",
    "random_indices = np.random.randint(0, array_size[0], size=(num_points, 3))\n",
    "for idx in random_indices:\n",
    "    large_array[tuple(idx)] = True\n",
    "\n",
    "# Test the dilation function with a spherical radius\n",
    "radius = 5\n",
    "\n",
    "start_time = time.time()\n",
    "dilated_array = dilate_3d_spherical(large_array, radius)\n",
    "end_time = time.time()\n",
    "\n",
    "time_taken = end_time - start_time\n",
    "time_taken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
